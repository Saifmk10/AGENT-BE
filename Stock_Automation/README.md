# Stock Automation â€“ Backend Module

## Overview

The **Stock_Automation** module is a backend-focused Python package designed to automate stock-related workflows such as data collection, analysis, and API exposure. The structure follows a **Dockerized, service-oriented design**, where each major responsibility (data collection, analysis, APIs) is isolated into its own container-ready module.

This folder acts as a **self-contained backend system** that can be plugged into a larger agent or automation platform.

---

## High-Level Architecture

```
Stock_Automation/
â”‚
â”œâ”€â”€ DATA_COLLECTION_DOCKER/
â”‚   â”œâ”€â”€ Data_fetching_from_db/          # Firebase data retrieval
â”‚   â”œâ”€â”€ Stock_price_fetching/           # Price collection via APIs
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ run.py                          # Entry point
â”‚
â”œâ”€â”€ ANALYSIS_GMAIL_DOCKER/
â”‚   â”œâ”€â”€ Stock_analysis_modules/         # Data analysis & statistics
â”‚   â”œâ”€â”€ Daily_stock_analysis/           # Daily reports & JSON conversion
â”‚   â”œâ”€â”€ Backend_to_user_sender/         # Email & message delivery
â”‚   â”œâ”€â”€ Csv_path_cleaner/               # Data cleanup utilities
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ runDailyAnalysis.py
â”‚   â”œâ”€â”€ runGmail.py
â”‚   â””â”€â”€ runMessage.py
â”‚
â”œâ”€â”€ API_ENDPOINTS_DOCKER/
â”‚   â”œâ”€â”€ stock_endpoints/
â”‚   â”‚   â”œâ”€â”€ options/                    # Stock search & pricing
â”‚   â”‚   â””â”€â”€ trends/                     # Market trends (gainers, losers, active)
â”‚   â”œâ”€â”€ main.py                         # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ environment/                        # Environment configuration
â”œâ”€â”€ __init__.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ doc.txt
```

Each major folder is designed to be **Dockerized independently**, making the system scalable and modular.

---

## Folder & File Breakdown

### ğŸ“ DATA_COLLECTION_DOCKER/

**Purpose:**
Responsible for **collecting raw stock data** from external sources and databases.

**Key Responsibilities:**
- Fetch live stock prices from financial APIs
- Retrieve user-subscribed stocks from Firebase
- Normalize and store raw market data in CSV format
- Match user-friendly stock names to ticker symbols using fuzzy logic

**Key Components:**
- `Data_fetching_from_db/` â€“ Queries Firebase for user subscriptions and stock lists
- `Stock_price_fetching/` â€“ Fetches prices via API and writes to CSV files
- `run.py` â€“ Orchestrates the data collection pipeline

**Data Flow:**
1. Connects to Firebase to get subscribed users and their stocks
2. Calls stock price API endpoints
3. Writes price data to user-organized CSV files
4. Feeds data to analysis services

---

### ğŸ“ ANALYSIS_GMAIL_DOCKER/

**Purpose:**
Responsible for **processing, analyzing stock data, and delivering insights** to users via email and other channels.

**Key Responsibilities:**
- Statistical analysis of stock prices (mean, median, std, OHLC)
- Daily report generation in JSON and HTML formats
- AI-powered stock interpretation and summaries
- Email delivery of analysis reports
- Data cleanup to prevent storage buildup

**Key Components:**
- `Stock_analysis_modules/` â€“ Pandas-based statistical analysis
- `Daily_stock_analysis/` â€“ Daily report generation and JSON conversion
- `Backend_to_user_sender/` â€“ Email composition and delivery
- `Csv_path_cleaner/` â€“ Cleanup of processed CSV files

**Data Flow:**
1. Reads CSV files from `DATA_COLLECTION_DOCKER`
2. Performs statistical analysis using Pandas
3. Generates daily reports in JSON format
4. Formats HTML emails with analysis insights
5. Sends emails to subscribed users
6. Cleans up processed files

---

### ğŸ“ API_ENDPOINTS_DOCKER/

**Purpose:**
Serves as the **public API layer** for the stock automation system.

**Key Responsibilities:**
- Expose REST endpoints for stock queries
- Provide trending stock data (gainers, losers, most active)
- Allow real-time stock price lookups
- Enable fuzzy search for stock names

**Key Endpoints:**
- `GET /stock/{symbol}` â€“ Fetch price data for a specific stock
- `GET /search/{symbol}` â€“ Search stocks by name
- `GET /gainer` â€“ Get top gaining stocks
- `GET /looser` â€“ Get top losing stocks
- `GET /mostActive` â€“ Get most active stocks

**Framework:** FastAPI with CORS support

**Data Flow:**
1. Receives requests from frontend or external services
2. Scrapes or queries stock data
3. Uses fuzzy matching for stock name resolution
4. Returns JSON responses

---

## System Architecture & Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Sources                         â”‚
â”‚              (Firebase, Stock APIs, Web Scraping)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   DATA_COLLECTION_DOCKER       â”‚
        â”‚  â€¢ Fetch user subscriptions    â”‚
        â”‚  â€¢ Collect stock prices        â”‚
        â”‚  â€¢ Store in CSV by user/stock  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ANALYSIS_GMAIL_DOCKER         â”‚
        â”‚  â€¢ Statistical analysis        â”‚
        â”‚  â€¢ Generate daily reports      â”‚
        â”‚  â€¢ Create HTML emails          â”‚
        â”‚  â€¢ Send to users               â”‚
        â”‚  â€¢ Cleanup data                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  User Email â”‚      â”‚ API_ENDPOINTS_DOCKERâ”‚
    â”‚  (Reports)  â”‚      â”‚ (REST API Layer)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Features

### 1. **Data Collection Pipeline**
- Automated stock price fetching
- Multi-user support with per-user CSV organization
- Fuzzy matching for stock name normalization
- Concurrent data fetching for performance

### 2. **Analysis Engine**
- Comprehensive statistical analysis (mean, median, std, quartiles)
- OHLC (Open-High-Low-Close) calculations
- Price volatility and movement analysis
- Percentage change calculations

### 3. **Email Delivery**
- HTML-formatted stock analysis reports
- Per-user customized summaries
- Scheduled daily/weekly deliveries
- Beautiful, responsive email templates

### 4. **REST API**
- FastAPI-based endpoints
- Real-time stock price lookups
- Market trend data (gainers, losers, most active)
- Fuzzy search for user-friendly stock discovery
- CORS-enabled for frontend integration

### 5. **Data Management**
- Organized CSV file structure per user
- JSON-based daily report archives
- Automatic cleanup of processed files
- Timestamp tracking for data integrity

---

## Technology Stack

| Component | Technology |
|-----------|-----------|
| Language | Python 3.11+ |
| Backend Framework | FastAPI |
| Data Processing | Pandas, NumPy |
| Database | Firebase Firestore |
| Containerization | Docker, Docker Compose |
| Web Scraping | BeautifulSoup4, Requests |
| Fuzzy Matching | RapidFuzz |
| Email | yagmail |
| Task Scheduling | Cron (external) |
| AI/LLM | Google Generative AI (Gemini) |

---

## Environment Setup

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- Firebase credentials (JSON key file)
- API keys for stock and AI services

### Installation

**1. Clone the repository:**
```bash
git clone <repository-url>
cd Stock_Automation
```

**2. Install dependencies:**
```bash
pip install -r requirements.txt
```

**3. Set environment variables:**
```bash
export DOCKER_PATH="/path/to/data/directory"
export GEMINI_API_KEY="your-api-key"
```

**4. Add Firebase credentials:**
Place your Firebase service account JSON file in:
- `DATA_COLLECTION_DOCKER/Data_fetching_from_db/`
- `ANALYSIS_GMAIL_DOCKER/Daily_stock_analysis/`

---

## Running the Services

### Option 1: Docker Compose

```bash
# Start data collection service
docker-compose up -d fetcher

# Start analysis service
docker-compose up -d analyzer

# Start API endpoints
docker-compose up -d api
```

### Option 2: Manual Execution

**Data Collection:**
```bash
cd DATA_COLLECTION_DOCKER
python run.py
```

**Daily Analysis:**
```bash
cd ANALYSIS_GMAIL_DOCKER
python runDailyAnalysis.py
```

**Email Delivery:**
```bash
cd ANALYSIS_GMAIL_DOCKER
python runGmail.py
```

**API Server:**
```bash
cd API_ENDPOINTS_DOCKER
uvicorn main:app --host 0.0.0.0 --port 1555
```

---

## Scheduled Execution

Services are orchestrated using cron jobs:

```bash
# Data collection: 9:20 AM on weekdays
20 9 * * 1-5 /path/to/docker/compose/up fetcher

# Stop collection: 3:45 PM on weekdays
45 15 * * 1-5 /path/to/docker/compose/stop fetcher

# Start analysis: 3:46 PM on weekdays
46 15 * * 1-5 /path/to/docker/compose/up analyzer

# Stop analysis: 4:00 PM on weekdays
0 16 * * 1-5 /path/to/docker/compose/stop analyzer
```

---

## Database Schema (Firebase)

```
Users/
â”œâ”€â”€ {userId}/
â”‚   â”œâ”€â”€ Email: string
â”‚   â”œâ”€â”€ Agents/
â”‚   â”‚   â””â”€â”€ Finance/
â”‚   â”‚       â”œâ”€â”€ Stock_Added/
â”‚   â”‚       â”‚   â””â”€â”€ {stockId}/
â”‚   â”‚       â”‚       â””â”€â”€ stockName: string
â”‚   â”‚       â””â”€â”€ Stock_Data/
â”‚   â”‚           â””â”€â”€ IntraDay/
â”‚   â”‚               â””â”€â”€ Data/
â”‚   â”‚                   â””â”€â”€ {timestamp}/
â”‚   â”‚                       â”œâ”€â”€ last_added: timestamp
â”‚   â”‚                       â””â”€â”€ DATA: object
```

---

## File Organization

```
/data/
â”œâ”€â”€ csvFiles/
â”‚   â””â”€â”€ {user-email}/
â”‚       â””â”€â”€ {stock-name}.csv
â””â”€â”€ reports/
    â””â”€â”€ {user-email}/
        â””â”€â”€ {date}.html (or .json)
```

---

## API Endpoints (Development)

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| GET | `/stock/{symbol}` | Fetch stock price & volume |
| GET | `/search/{symbol}` | Search stock by name |
| GET | `/gainer` | Top gaining stocks |
| GET | `/looser` | Top losing stocks |
| GET | `/mostActive` | Most active stocks |

**Base URL:** `http://localhost:1555` (local) or configured production URL

---

## Best Practices

### Data Modeling
- Store stock data per user to minimize cross-partition queries
- Use hierarchical directory structure for fast file access
- Archive old reports to prevent storage bloat

### Performance
- Use concurrent data fetching with ThreadPoolExecutor
- Implement retry logic for network failures
- Cache ticker symbols and company names locally

### Error Handling
- Log all exceptions with context
- Implement graceful degradation for API failures
- Monitor cron job execution with logging

### Security
- Store sensitive credentials in environment variables
- Never commit API keys or authentication tokens
- Use CORS restrictions in production
- Validate all user inputs before processing

---

## Troubleshooting

### No data in CSVs
- Verify Firebase credentials are valid
- Check if users have subscribed to the Finance agent
- Ensure API rate limits aren't exceeded

### Email not sending
- Verify SMTP credentials and permissions
- Check firewall rules for outgoing email
- Review email logs for authentication errors

### API endpoints failing
- Verify stock symbol format (e.g., `ASHOKLEY` for NSE stocks)
- Check if web scraping selectors have changed
- Review rate limiting from financial websites

### Storage growing too large
- Verify cleanup job is running (`cleaningData()`)
- Check if archive process is functioning
- Monitor disk space usage

---

## Contributing

1. Create a feature branch from `main`
2. Follow PEP 8 code style
3. Add docstrings to new functions
4. Test locally before submitting
5. Update this README for significant changes

---

## Architecture Notes

### Design Philosophy
- **Modularity:** Each service is independent and Dockerized
- **Scalability:** Services can be deployed and scaled separately
- **Maintainability:** Clear separation of concerns
- **Extensibility:** Easy to add new data sources or analysis methods

### Technology Decisions
- **Firebase:** Provides real-time user management and flexibility
- **FastAPI:** High-performance, easy to deploy, great for APIs
- **Pandas:** Industry-standard for data analysis
- **Docker:** Ensures consistency across environments
- **Cron:** Simple, reliable scheduling for batch jobs

---

## License

[Add your license here]

---

## Support

For issues, questions, or contributions, please:
- Open an issue on the repository
- Contact the development team
- Review the documentation in `/docs` folder

---

## Changelog

### v1.0.0
- Initial release with data collection, analysis, and API services
- Email delivery automation
- Cron-based scheduling

---

**Last Updated:** 8 feb 2025
**Maintained By:** saifmk.online